---
title: "Analysis of the properties influencing film rating over 7"
subtitle: "student number: 3026884, 2995341, 2897872, 2971937, 3048441"
number-sections: true
format: 
  html:
    embed-resources: true
    code-tools: true
  pdf: default
editor_options: 
  chunk_output_type: console
execute:
  echo: true
  eval: true
  warning: false
  message: false
---

```{r}
#| echo: false
#| warning: false
#| message: false
library(dplyr)
library(ggplot2)
library(tidyr)
library(caret)
library(car)
library(MASS)
library(randomForest)
library(glmnet)
library(skimr)
library(corrplot)
library(GGally)
library(psych)
```

## Introduction

The goal of this analysis is to determine which film properties influence whether a movie is rated above 7 on IMDB. We will use a Generalized Linear Model (GLM) along with other machine learning models for comparison.

## Data Loading and Cleaning

```{r}
film <- read.csv("C:\\Users\\shiyi\\Downloads\\dataset07 (1).csv")

# Check structure and missing values
str(film)
skim(film)

# Fill missing numeric values with mean
film <- film %>%
  mutate(across(where(is.numeric), ~ ifelse(is.na(.), mean(., na.rm = TRUE), .)))

# Convert categorical variables
film$genre <- as.factor(film$genre)


# I tried to just list-wise deleted the missing value, and the models based on this method has lower AICs.
```

## Exploratory Data Analysis

```{r}
summary(film)

#Histograms of IMDB ratings 
ggplot(film, aes(x = rating)) +
  geom_histogram(binwidth = 0.1, fill = "steelblue", color = "black") +
  labs(x = "IMDB Rating", y = "Frequency", title = "Distribution of IMDB Ratings") +
  scale_x_continuous(breaks = seq(0, 10, by = 1))
#
#The x-axis of this chart had too few tick marks, so I added a few more. I also made each bar slightly narrower (modified plot below).
```

```{r}
#
#modified plot
ggplot(film, aes(x = rating)) +
  geom_histogram(binwidth = 0.1, fill = "steelblue", color = "black") +
  labs(x = "IMDB Rating", y = "Frequency", title = "Distribution of IMDB Ratings") +
  scale_x_continuous(breaks = seq(0, 10, by = 1))
```

```{r}
#Barplot of Film Counts by Genre
ggplot(film, aes(x = factor(genre))) +
  geom_bar(fill = "skyblue", color = "black") +
  labs(x = "Genre", y = "Count of Films", title = "Count of Films by Genre")

```

```{r}
#Scatterplot of Budget vs Rating
ggplot(film, aes(x = budget, y = rating)) +
  geom_point(color = "steelblue") +
  labs(x = "Budget (Millions)", y = "IMDB Rating", title = "Rating vs Budget")+
  geom_hline(yintercept = 7, linetype = "dashed", color = "red", size = 1)
```

```{r}
#Scatterplot of Votes vs Rating
ggplot(film, aes(x = votes, y = rating)) +
  geom_point(alpha = 0.5) +
  labs(title = "Votes vs IMDB Rating", x = "Number of Votes", y = "IMDB Rating")+
  geom_hline(yintercept = 7, linetype = "dashed", color = "red", size = 1)

```

```{r}
#Scatterplot of Log(Votes) vs Rating
ggplot(film, aes(x = log(votes), y = rating)) +
  geom_point(alpha = 0.5) +
  labs(title = "Log(Votes) vs IMDB Rating", x = "Log(Votes)", y = "IMDB Rating")+
  geom_hline(yintercept = 7, linetype = "dashed", color = "red", size = 1)
```

```{r}
#Scatterplot of Film Length vs Rating
ggplot(film, aes(x = length, y = rating)) +
  geom_point(alpha = 0.5) +
  labs(title = " Film Length vs IMDB Rating", x = " Film Length (Minutes)", y = "IMDB Rating")+
  geom_hline(yintercept = 7, linetype = "dashed", color = "red", size = 1)

# From this plot, we can see that all the data is actually divided into two groups: one for short films and one for long films. So I think we can introduce a new variable, long_film, where films shorter than 40 minutes are classified as short films, and those longer than 40 minutes as long films. Although the genre category includes "Short," some films that belong to other genres are also under 40 minutes, or even just a few minutes long. In the code block below, I show the number of films under 40 minutes across different genres.

```

```{r}
film %>%
  filter(length < 40) %>%
  count(genre)
# 
# The code for creating this new variable is as follows. If this variable is added, some adjustments to the subsequent code may be needed:
 film1 <- film %>% mutate(long_film = ifelse(length < 40, "short", "long"))
```

```{r}
#Boxplot of Year vs Rating by duration
film$year_group <- cut(film$year, 
                             breaks = c(1894, 1904, 1914, 1924, 1934, 1944, 1954, 1964, 1974, 1984, 1994,2006), 
                             labels = c(1:11),right=FALSE)  
ggplot(film, aes(x = year_group, y = rating, fill = year_group)) +
  geom_boxplot(na.rm = TRUE) +
  labs(title = "IMDB Rating by Year Group", x = "Year Group", y = "IMDB Rating") +
  geom_hline(yintercept = 7, linetype = "dashed", color = "red", size = 1)+
  scale_fill_discrete(name = "Year Group", 
                      labels = c("1894-1904", 
                                 "1904-1914", 
                                 "1914-1924", 
                                 "1924-1934", 
                                 "1934-1944", 
                                 "1944-1954", 
                                 "1954-1964", 
                                 "1964-1974", 
                                 "1974-1984", 
                                 "1984-1994", 
                                 "1994-2005")) 

```

```{r}
# Boxplot of Binary rating
film$rating_group <- ifelse(film$rating > 7, "Above 7", "Below or Equal to 7")
ggplot(film, aes(x = rating_group, y = rating, fill = rating_group)) +
  geom_boxplot() +
  labs(title = "IMDB Rating by Rating Group", x = "Rating Group", y = "IMDB Rating") 

```

## Creating the Binary Outcome Variable

```{r}
film$rating_binary <- ifelse(film$rating > 7, 1, 0)
```

## Correlation Analysis

```{r}
corr_matrix <- film %>%
  dplyr::select(where(is.numeric)) %>% 
  cor(use = "complete.obs")
corrplot(corr_matrix, method = "circle")

#This matrix does not display the correlation values, making it less intuitive. So, in the modified version below, I included both colors and numerical values (modified plot below).
```

```{r}
# modified plot
ggcorr(film, label = TRUE, label_round = 2, low = "blue", high = "red")
```

## Variable Selection

```{r}
# Univariate Logistic Regression
variables <- c("year", "length", "budget", "votes")
univariate_results <- sapply(variables, function(var) {
  model <- glm(rating_binary ~ get(var), data = film, family = binomial)
  summary(model)$coefficients[2,4]
})
univariate_results
```

## Stepwise Regression

```{r}
full_model <- glm(rating_binary ~ year + length + budget + votes + genre, data = film, family = binomial)
stepwise_model <- stepAIC(full_model, direction = "both")
summary(stepwise_model)
```

```{r}

# This code block presents the new model after adding the long_film variable, so you can compare it with the previous model.
new_model <- glm(rating_binary ~ length + budget + votes + genre + long_film, data = film1, family = binomial)
```

## Multicollinearity Check (VIF)

```{r}
vif_values <- vif(stepwise_model)
vif_values
```

## Principal Component Analysis (If Needed)

```{r}
film_numeric <- film %>% 
  dplyr::select(year, length, budget, votes)
pca <- prcomp(film_numeric, center = TRUE, scale = TRUE)
summary(pca)
```

## Model Comparison

```{r}
# Logistic Regression
logit_model <- glm(rating_binary ~ year + budget + votes, data = film, family = binomial)
summary(logit_model)

# Random Forest
rf_model <- randomForest(rating_binary ~ year + budget + votes, data = film, ntree = 500, importance = TRUE)
print(rf_model)
varImpPlot(rf_model)

# Lasso Regression
x <- model.matrix(rating_binary ~ year + budget + votes, data = film)[,-1]
y <- film$rating_binary
lasso_model <- cv.glmnet(x, y, alpha = 1, family = "binomial")
coef(lasso_model, s = "lambda.min")
```

## Model Evaluation and Prediction

```{r}
# Model Performance Metrics
logit_pred <- predict(logit_model, type = "response")
logit_class <- ifelse(logit_pred > 0.5, 1, 0)
table(logit_class, film$rating_binary)

# Random Forest Prediction
rf_pred <- predict(rf_model, type = "class")
table(rf_pred, film$rating_binary)
```

## Conclusion

Based on the analysis, we found that budget and votes are significant predictors of IMDB ratings. The logistic regression and random forest models provided strong predictive capabilities, while PCA did not significantly improve the model. Further improvements could be made using ensemble methods or additional feature engineering.
